{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe91e85e-ff81-4a6f-a4a5-129fab5b2809",
   "metadata": {},
   "source": [
    "**Building an AI Agent from Scratch using LangChain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6b3f6-7f26-4e57-b35e-97e0bebed871",
   "metadata": {},
   "source": [
    "Installing the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8356df-44e9-40ad-894d-bbc252f0774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (0.3.68)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (3.12.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (0.4.5)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: langgraph in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph) (0.3.68)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph) (2.1.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph) (0.5.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph) (0.1.72)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: anyio in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -U langchain langchain_openai tavily-python\n",
    "# !pip install -U tavily-python\n",
    "!pip install -U langchain-community\n",
    "# !pip install -U langchain langchain-openai langchain-tavily\n",
    "!pip install --upgrade langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15f892-c8c5-4cfc-9bf2-3db497e1a445",
   "metadata": {},
   "source": [
    "Setting API keys for OpenAI (LLM being used) and Tavily (Search tool being used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af7c5d5-ae1f-47d2-a635-96a9255447d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa758a70-1097-4b08-95af-4abc27115e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI key loaded: True\n",
      "✅ Tavily key loaded: True\n",
      "✅ Langchain key loaded: True\n"
     ]
    }
   ],
   "source": [
    "# #To input the keys manualyy\n",
    "# import os\n",
    "# import getpass\n",
    "\n",
    "# os.environ[\"OPEN_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "# os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API Key:\")\n",
    "\n",
    "# To load the keys from the env created\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Correct variable names\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "langchain_key=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Set them as environment variables explicitly (for LangChain/OpenAI to pick them up)\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "os.environ[\"TAVILY_API_KEY\"] = tavily_key\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=langchain_key\n",
    "\n",
    "# Confirm\n",
    "print(\"✅ OpenAI key loaded:\", bool(openai_key))\n",
    "print(\"✅ Tavily key loaded:\", bool(tavily_key))\n",
    "print(\"✅ Langchain key loaded:\", bool(langchain_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e3f5b-4208-4a2b-b8d8-a0b69dd780ef",
   "metadata": {},
   "source": [
    "**Now let's create the LangChain AI Agents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a06729-fb9e-4b68-a61f-246aacc5a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langgraph\n",
      "Version: 0.5.4\n",
      "Summary: Building stateful, multi-actor applications with LLMs\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License-Expression: MIT\n",
      "Location: c:\\users\\akino\\anaconda3\\envs\\nlp_project\\lib\\site-packages\n",
      "Requires: langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph-sdk, pydantic, xxhash\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1653ed-bca5-487c-a6fa-2604b242bd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akino\\AppData\\Local\\Temp\\ipykernel_1980\\4009537192.py:6: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tools =[TavilySearchResults(max_results=10)]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools =[TavilySearchResults(max_results=10)]\n",
    "\n",
    "#Prompt type used\n",
    "prompt= hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "#Choose the LLM that will drive the agent\n",
    "# llm= ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True\n",
    "llm= ChatOpenAI(model=\"gpt-4\", streaming=True)               \n",
    "\n",
    "#OpenAI Function Agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0b6ec-803e-428e-b573-e247f476902b",
   "metadata": {},
   "source": [
    "**Now let's define the graph state**\n",
    "\n",
    "input-->chat_history---->intermediate_steps---->agent_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57fb65e-c48e-4c81-9d5b-b894b58c42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union, Tuple\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    #Input string\n",
    "    input:str\n",
    "    # Previous message list in the conversation\n",
    "    chat_history: list[BaseMessage]\n",
    "    # The outcome of a given call to the agent\n",
    "    # Needs 'None' as a valid type, since this is what this will start as\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    # Actions and Observations\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2436aee0-68ea-45e4-ab5c-75ab0741bd61",
   "metadata": {},
   "source": [
    "**Defining the nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5482a485-6f9b-44bc-a69d-fa9bac859fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish, AgentAction\n",
    "\n",
    "# Custom tool executor\n",
    "def custom_tool_executor(agent_action, tools):\n",
    "    for tool in tools:\n",
    "        if tool.name == agent_action.tool:\n",
    "            return tool.invoke(agent_action.tool_input)\n",
    "    raise ValueError(f\"Tool '{agent_action.tool}' not found.\")\n",
    "\n",
    "# Agent definition\n",
    "def run_agent (data):\n",
    "    agent_outcome = agent_runnable.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "# Function execution tool\n",
    "def execute_tools(data):\n",
    "    # most recent agent_outcome \n",
    "    agent_action = data['agent_outcome']\n",
    "    output = custom_tool_executor(agent_action, tools)\n",
    "    return{\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "#conditional edge logic\n",
    "def should_continue(data):\n",
    "    # FOR AgentFinish, return 'exit' string\n",
    "    if isinstance(data['agent_outcome'], AgentFinish):\n",
    "        return \"end\"\n",
    "    \n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacaebc0-f260-4bbf-9a3c-6ac406e6a919",
   "metadata": {},
   "source": [
    "**Defining the graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0319c1-0eb9-44eb-9ca5-a758e6a980b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "#Defining a new graph\n",
    "workflow=StateGraph(AgentState)\n",
    "\n",
    "#Two nodes to iterate within\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "#Entry point as an agent\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "#We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # Defining the start node as an agent\n",
    "    \"agent\",\n",
    "    # Determine which node is next\n",
    "    should_continue,\n",
    "    # Continue or end\n",
    "    {\n",
    "        \"continue\":\"action\",\n",
    "        # else, finish\n",
    "        \"end\":END\n",
    "    }\n",
    ")\n",
    "\n",
    "#adding an edge\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Compiling\n",
    "app=workflow.compile()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b5e109f-2485-4e0b-b2a7-344a8b220062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'The processdoctorgroup on linkedin'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'The processdoctorgroup on linkedin'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"The processdoctorgroup on linkedin\"\\n}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4-0613', 'service_tier': 'default'}, id='run--5184d75c-25fa-46b9-a398-b332d01dd314-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'The processdoctorgroup on linkedin'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'The processdoctorgroup on linkedin'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"The processdoctorgroup on linkedin\"\\n}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4-0613', 'service_tier': 'default'}, id='run--5184d75c-25fa-46b9-a398-b332d01dd314-0')]), '[{\\'title\\': \\'The ProcessDoctorGroup (@_thepdg) • Instagram photos and videos\\', \\'url\\': \\'https://www.instagram.com/_thepdg/\\', \\'content\\': \\'www.linkedin.com/company/theprocessdoctorgroup/about ... The ProcessDoctorGroup (The ProcessDoctorGroup): Engineering the Future of Industry ✨ At\\', \\'score\\': 0.7978881}, {\\'title\\': \\'Ayooluwa Akintola (PhD, PMP®, MIAENG) - Machine ... - LinkedIn\\', \\'url\\': \\'https://www.linkedin.com/in/ayooluwa-akintola-phd-pmp%C2%AE-miaeng-43a4389a\\', \\'content\\': \\'Experience ; Machine Learning-AI Engineer-Research & Development. The ProcessDoctorGroup. Jun 2025 ; Research Assistant. West Virginia University. Aug 2021\\', \\'score\\': 0.75809944}, {\\'title\\': \\'Driving Innovation, Transforming the Future | The ProcessDoctorGroup\\', \\'url\\': \\'https://www.linkedin.com/posts/theprocessdoctorgroup_process-productdevelopment-product-activity-7340568368749449217-34A8\\', \\'content\\': \"The ProcessDoctorGroup\\'s Post. View organization page for The ProcessDoctorGroup. The ProcessDoctorGroup. 20 followers. 1mo Edited. Report this\", \\'score\\': 0.6543875}, {\\'title\\': \\'Engineering the Future of Industry | The ProcessDoctorGroup\\', \\'url\\': \\'https://www.linkedin.com/posts/theprocessdoctorgroup_sustainabletechnologies-advancedresearchanddevelopment-activity-7347826381851926528-fOnT\\', \\'content\\': \"The ProcessDoctorGroup\\'s Post. View organization page for The ProcessDoctorGroup · The ProcessDoctorGroup. 19 followers. 1w Edited.\", \\'score\\': 0.61112726}, {\\'title\\': \\'3 \"Ayooluwa Akintola\" profiles - LinkedIn\\', \\'url\\': \\'https://www.linkedin.com/pub/dir/Ayooluwa/Akintola\\', \\'content\\': \\'The ProcessDoctorGroup, +5 more. West Virginia University, +5 more. Ayooluwa Akintola. Marketer, Sales person,Analyst,Critical Thinker\\', \\'score\\': 0.6016175}, {\\'title\\': \"Why in my simulation Aspen plus doesn\\'t consider solid reaction?\", \\'url\\': \\'https://www.researchgate.net/post/Why_in_my_simulation_Aspen_plus_doesnt_consider_solid_reaction\\', \\'content\\': \\'The ProcessDoctorGroup. From the configuration of Aspe Plus, CSTR does not really support solid reactions. There should be a way around that\\', \\'score\\': 0.17204693}]')]}\n",
      "----\n",
      "{'agent_outcome': AgentFinish(return_values={'output': 'I found several pages related to The ProcessDoctorGroup on LinkedIn:\\n\\n1. The ProcessDoctorGroup [@_thepdg](https://www.instagram.com/_thepdg/) on Instagram mentions `www.linkedin.com/company/theprocessdoctorgroup/about`. They are involved in engineering the future of the industry.\\n\\n2. Dr. Ayooluwa Akintola is one person associated with The ProcessDoctorGroup. He is a [Machine Learning-AI Engineer-Research & Development](https://www.linkedin.com/in/ayooluwa-akintola-phd-pmp%C2%AE-miaeng-43a4389a) at the ProcessDoctorGroup since June 2025.\\n\\n3. The company frequently posts about driving innovation and transforming the future, as can be seen from one of their [posts](https://www.linkedin.com/posts/theprocessdoctorgroup_process-productdevelopment-product-activity-7340568368749449217-34A8) on LinkedIn. \\n\\n4. Another [post](https://www.linkedin.com/posts/theprocessdoctorgroup_sustainabletechnologies-advancedresearchanddevelopment-activity-7347826381851926528-fOnT) highlights their involvement in engineering the future of industry.\\n\\nPlease visit the individual URLs for complete details and to verify the information.\\n'}, log='I found several pages related to The ProcessDoctorGroup on LinkedIn:\\n\\n1. The ProcessDoctorGroup [@_thepdg](https://www.instagram.com/_thepdg/) on Instagram mentions `www.linkedin.com/company/theprocessdoctorgroup/about`. They are involved in engineering the future of the industry.\\n\\n2. Dr. Ayooluwa Akintola is one person associated with The ProcessDoctorGroup. He is a [Machine Learning-AI Engineer-Research & Development](https://www.linkedin.com/in/ayooluwa-akintola-phd-pmp%C2%AE-miaeng-43a4389a) at the ProcessDoctorGroup since June 2025.\\n\\n3. The company frequently posts about driving innovation and transforming the future, as can be seen from one of their [posts](https://www.linkedin.com/posts/theprocessdoctorgroup_process-productdevelopment-product-activity-7340568368749449217-34A8) on LinkedIn. \\n\\n4. Another [post](https://www.linkedin.com/posts/theprocessdoctorgroup_sustainabletechnologies-advancedresearchanddevelopment-activity-7347826381851926528-fOnT) highlights their involvement in engineering the future of industry.\\n\\nPlease visit the individual URLs for complete details and to verify the information.\\n')}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs={\"input\":\"Anything about The processdoctorgroup on linkedin\", \"chat_history\":[]}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
